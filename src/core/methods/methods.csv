num,category,method_name,description,output_pattern
1,collaboration,Stakeholder Round Table,"[TRIGGER]: Use when gathering requirements or finding balanced solutions across competing interests. [STEPS]: (1) Identify 3-5 key stakeholder personas (2) Have each persona articulate their primary concern and success criteria (3) Find points of alignment across personas (4) Identify genuine conflicts that require trade-offs (5) Synthesize into balanced recommendation. [FORCED]: If all personas agree too easily you have not represented diverse enough viewpoints. [KEY QUESTION]: What solution satisfies the most critical needs of each stakeholder? [ANTI-PATTERN]: Creating strawman personas who easily concede to your preferred solution.",perspectives → synthesis → alignment
2,collaboration,Expert Panel Review,"[TRIGGER]: Use when technical depth and peer review quality are needed. [STEPS]: (1) Identify 3+ domain experts with different specializations (2) Have each expert analyze independently (3) Compare findings and note agreements and disagreements (4) Discuss disagreements to reach reasoned consensus (5) Document recommendations with confidence levels. [FORCED]: Experts must DISAGREE on at least one substantive point or analysis is too shallow. [KEY QUESTION]: What do experts with different viewpoints collectively recommend? [ANTI-PATTERN]: Experts rubber-stamping without genuine critical engagement.",expert views → consensus → recommendations
3,collaboration,Debate Club Showdown,"[TRIGGER]: Use when exploring controversial decisions or finding middle ground. [STEPS]: (1) Define the motion clearly (2) Assign PRO and CON personas (3) Each side presents 3 strongest arguments with evidence (4) Each side rebuts opponent's arguments (5) Moderator scores points and identifies strongest arguments from both sides (6) Synthesize into balanced conclusion. [FORCED]: The side you personally disagree with must have at least one argument you cannot fully rebut. [KEY QUESTION]: What is the strongest case for each position? [ANTI-PATTERN]: Setting up weak arguments for the side you want to lose.",thesis → antithesis → synthesis
4,collaboration,User Persona Focus Group,"[TRIGGER]: Use when validating features or discovering unmet needs. [STEPS]: (1) Define 3-5 distinct user personas with different goals and contexts (2) Present proposal or feature to each persona (3) Record each persona's gut reaction concerns and questions (4) Identify patterns across personas (5) Prioritize concerns by frequency and severity. [FORCED]: At least one persona must HATE the proposal or you have not included diverse enough users. [KEY QUESTION]: What real user frustrations does this proposal address or create? [ANTI-PATTERN]: Creating personas who all conveniently love your idea.",reactions → concerns → priorities
5,collaboration,Time Traveler Council,"[TRIGGER]: Use when gaining perspective on long-term consequences vs short-term pressures. [STEPS]: (1) Define past-you (1-5 years ago) present-you and future-you (1-5 years ahead) (2) Past-you shares what you wish you had known (3) Future-you shares what you wish present-you would do differently (4) Present-you weighs both perspectives against current constraints (5) Identify decisions that serve all three time horizons. [FORCED]: Future-you must identify at least one thing present-you is about to regret. [KEY QUESTION]: What decision will I thank myself for in 5 years? [ANTI-PATTERN]: Future-you conveniently validating what present-you already wants to do.",past wisdom → present choice → future impact
6,collaboration,Cross-Functional War Room,"[TRIGGER]: Use when trade-offs between feasibility desirability and viability need resolution. [STEPS]: (1) Assign PM Engineer and Designer personas (2) PM defines what users want and business value (3) Engineer defines technical constraints and effort (4) Designer defines user experience requirements (5) Find solution that satisfies critical constraints from all three (6) Document what was sacrificed and why. [FORCED]: Each persona must veto at least one proposal before final solution is reached. [KEY QUESTION]: What is the smallest viable solution that satisfies all functions? [ANTI-PATTERN]: One function dominating without genuine pushback from others.",constraints → trade-offs → balanced solution
7,collaboration,Mentor and Apprentice,"[TRIGGER]: Use when you need to surface hidden assumptions through teaching. [STEPS]: (1) Senior expert explains concept or solution (2) Apprentice asks naive questions starting with 'why' and 'what if' (3) Expert must answer without dismissing (4) Apprentice identifies gaps in explanation (5) Expert revises explanation to fill gaps. [FORCED]: Apprentice must ask at least 3 questions that make Expert pause and think. [KEY QUESTION]: What do I assume everyone knows that actually requires explanation? [ANTI-PATTERN]: Apprentice asking softball questions or Expert dismissing questions as irrelevant.",explanation → questions → deeper understanding
8,collaboration,Good Cop Bad Cop,"[TRIGGER]: Use when you need both encouragement and criticism in balanced assessment. [STEPS]: (1) Good Cop identifies 3 genuine strengths with specific evidence (2) Bad Cop identifies 3 genuine weaknesses with specific evidence (3) For each weakness Good Cop proposes how strengths can address it (4) For each strength Bad Cop identifies how it could become weakness (5) Synthesize into balanced view. [FORCED]: Good Cop and Bad Cop must genuinely disagree on at least one assessment. [KEY QUESTION]: What are the real strengths to build on and real weaknesses to address? [ANTI-PATTERN]: Good Cop being sycophantic or Bad Cop being destructively negative.",encouragement → criticism → balanced view
9,collaboration,Improv Yes-And,"[TRIGGER]: Use when generating unexpected creative directions through collaborative building. [STEPS]: (1) Start with initial idea seed (2) Persona A adds to idea with 'yes and...' (3) Persona B adds to that with 'yes and...' (4) Continue for 5+ rounds never blocking (5) Review the unexpected direction reached (6) Extract valuable elements from the journey. [FORCED]: The final idea must be unrecognizable from the starting idea or building was too conservative. [KEY QUESTION]: Where does unconstrained collaborative building lead? [ANTI-PATTERN]: Adding elements that subtly redirect back to predetermined conclusion.",idea → build → build → surprising result
10,collaboration,Customer Support Theater,"[TRIGGER]: Use when discovering real user frustrations and service gaps. [STEPS]: (1) Define angry customer persona with specific frustration (2) Customer describes problem with emotional context (3) Support rep investigates root cause (4) Rep proposes resolution (5) Customer responds with whether resolution is acceptable (6) Extract systemic prevention measures. [FORCED]: Customer must escalate at least once before being satisfied. [KEY QUESTION]: What is the real frustration behind the complaint? [ANTI-PATTERN]: Customer being easily satisfied with first response.",complaint → investigation → resolution → prevention
11,collaboration,Devil's Advocate Council,"[TRIGGER]: Use when stress-testing a proposal before commitment. [STEPS]: (1) Present proposal clearly (2) Assign 3 Devil's Advocates with different attack angles (cost/risk/ethics) (3) Each advocate presents strongest objection with evidence (4) Proposal defender must respond substantively (5) Rate which objections were successfully addressed vs remain valid (6) Decide proceed/modify/abandon. [FORCED]: At least one objection must survive and be incorporated into final decision. [KEY QUESTION]: What are the strongest arguments against this proposal? [ANTI-PATTERN]: Advocates raising easily dismissed objections.",proposal → attacks → defenses → refined decision
12,collaboration,Accountability Partners,"[TRIGGER]: Use when ensuring follow-through on commitments. [STEPS]: (1) Define specific commitment with deadline (2) Partner A states what they will do and by when (3) Partner B asks clarifying questions and identifies risks (4) Both agree on check-in schedule (5) At check-in Partner B asks for evidence of progress (6) If blocked both problem-solve. [FORCED]: Partner B must ask at least one uncomfortable question about likelihood of completion. [KEY QUESTION]: What specific evidence will show this is actually getting done? [ANTI-PATTERN]: Partners being too polite to push on accountability.",commitment → clarity → check-ins → evidence
13,collaboration,Retrospective Circle,"[TRIGGER]: Use when extracting learnings from completed work. [STEPS]: (1) Define the time period or project to review (2) Each persona shares what went well with specific examples (3) Each persona shares what could improve with specific examples (4) Identify root causes not just symptoms (5) Propose specific actionable changes (6) Assign ownership for each action. [FORCED]: At least one 'went well' must have a hidden downside and one 'improve' must have been partially successful. [KEY QUESTION]: What specific changes will we make based on this experience? [ANTI-PATTERN]: Vague observations without actionable outcomes.",well → improve → root causes → actions
14,collaboration,Red Team Briefing,"[TRIGGER]: Use when presenting to skeptical audience or preparing for tough questions. [STEPS]: (1) Present your case as you would to the actual audience (2) Red team identifies 5 toughest questions they would ask (3) For each question rate your prepared answer as strong/weak/missing (4) Develop stronger answers for weak/missing (5) Practice delivering under pressure. [FORCED]: At least 2 questions must initially have weak or missing answers. [KEY QUESTION]: What questions am I hoping they won't ask? [ANTI-PATTERN]: Red team asking questions you already have good answers for.",presentation → tough questions → answer quality → preparation
15,collaboration,Synthesis Council,"[TRIGGER]: Use when integrating findings from multiple analyses into coherent whole. [STEPS]: (1) List all findings from different methods or sources (2) Group findings by theme (3) Identify agreements across sources (4) Identify contradictions across sources (5) For contradictions determine which is more reliable and why (6) Create unified narrative that acknowledges uncertainty. [FORCED]: If no contradictions found you have not looked hard enough or sources are not independent. [KEY QUESTION]: What coherent story emerges from all evidence? [ANTI-PATTERN]: Cherry-picking findings that support predetermined conclusion.",findings → themes → agreements → contradictions → synthesis
16,advanced,Tree of Thoughts,"[TRIGGER]: Use when complex problem has multiple valid approaches to explore. [STEPS]: (1) Define the problem clearly (2) Generate 3+ distinct reasoning paths (3) Develop each path independently for 2-3 steps (4) Evaluate each path on explicit criteria (progress/feasibility/promise) (5) Prune clearly inferior paths (6) Continue developing promising paths (7) Select best final path with justification. [FORCED]: At least one initially promising path must be pruned after exploration. [KEY QUESTION]: Which reasoning path leads to the best solution? [ANTI-PATTERN]: Developing one path deeply while giving others superficial treatment.",paths → evaluation → selection
17,advanced,Graph of Thoughts,"[TRIGGER]: Use when ideas are interconnected and emergent patterns need discovery. [STEPS]: (1) List all relevant concepts as nodes (2) Draw edges between related concepts (3) Label edge types (causes/enables/conflicts/requires) (4) Identify clusters of highly connected nodes (5) Identify bridge nodes connecting clusters (6) Look for cycles and their implications (7) Identify isolated nodes that should be connected. [FORCED]: Graph must have at least one unexpected connection discovered through mapping. [KEY QUESTION]: What hidden relationships exist between ideas? [ANTI-PATTERN]: Drawing obvious connections without discovering new ones.",nodes → connections → patterns
18,advanced,Thread of Thought,"[TRIGGER]: Use when maintaining coherent reasoning across long contexts. [STEPS]: (1) Identify the core thread (main question or goal) (2) At each reasoning step connect back to thread explicitly (3) When introducing new information explain how it relates to thread (4) Periodically summarize thread progress (5) At conclusion trace how thread was followed from start to finish. [FORCED]: Every paragraph must have explicit connection to core thread or be removed. [KEY QUESTION]: How does each piece of reasoning serve the main goal? [ANTI-PATTERN]: Tangents that never reconnect to main thread.",context → thread → synthesis
19,advanced,Self-Consistency Validation,"[TRIGGER]: Use when high-stakes decisions require verification. [STEPS]: (1) Solve problem using approach A (2) Solve same problem independently using approach B (3) Solve same problem independently using approach C (4) Compare all three solutions (5) Where they agree high confidence (6) Where they disagree investigate which is correct (7) Resolve disagreements or flag uncertainty. [FORCED]: Approaches must be genuinely independent not variations of same method. [KEY QUESTION]: Do different approaches converge on the same answer? [ANTI-PATTERN]: Using approaches so similar they always agree.",approaches → comparison → consensus
20,advanced,Meta-Prompting Analysis,"[TRIGGER]: Use when optimizing your approach or methodology. [STEPS]: (1) Document current approach explicitly (2) Ask what assumptions does this approach make (3) Ask what could this approach miss (4) Generate alternative approaches (5) Compare approaches on explicit criteria (6) Select improved approach with justification. [FORCED]: Current approach must have at least one significant limitation identified. [KEY QUESTION]: How can my methodology itself be improved? [ANTI-PATTERN]: Concluding current approach is optimal without genuine alternatives considered.",current → analysis → optimization
21,advanced,Reasoning via Planning,"[TRIGGER]: Use when strategic planning requires modeling future states. [STEPS]: (1) Define current state precisely (2) Define goal state precisely (3) Identify operators (actions that change state) (4) Build plan from current to goal (5) Identify decision points in plan (6) At each decision point model consequences of choices (7) Select path that best reaches goal. [FORCED]: Plan must include at least one contingency for when primary path is blocked. [KEY QUESTION]: What sequence of actions gets from here to there? [ANTI-PATTERN]: Linear plan without contingencies.",model → planning → strategy
22,advanced,Abstraction Laddering,"[TRIGGER]: Use when problem needs reframing at different levels. [STEPS]: (1) State problem at current level (2) Go UP one level - why does this matter (3) Go UP again - why does THAT matter (4) Go DOWN one level - how specifically (5) Go DOWN again - what concrete steps (6) Find the level where problem is best addressed. [FORCED]: Going up must reveal that original framing was too narrow at least once. [KEY QUESTION]: At what level of abstraction is this problem best solved? [ANTI-PATTERN]: Staying at original level without exploring others.",concrete → abstract → concrete → optimal level
23,advanced,Analogical Reasoning,"[TRIGGER]: Use when problem might have solutions in other domains. [STEPS]: (1) Abstract the problem to its structural form (2) Search for analogous problems in other fields (3) Study how analogous problems were solved (4) Map solution back to original domain (5) Adapt solution to fit specific context (6) Validate adaptation works. [FORCED]: Analogy must come from domain that seems unrelated on surface. [KEY QUESTION]: Where has this type of problem been solved before? [ANTI-PATTERN]: Using superficially similar analogies from same domain.",structure → analogy → mapping → adaptation
24,advanced,Steelmanning,"[TRIGGER]: Use when engaging with opposing viewpoint fairly. [STEPS]: (1) Identify opposing position (2) State it in its STRONGEST form (3) Add supporting arguments opponent might not have made (4) Identify what would make this position correct (5) Only then critique the steelmanned version (6) Acknowledge what remains valid after critique. [FORCED]: Opponent should agree your steelman is fair or stronger than their own version. [KEY QUESTION]: What is the strongest possible version of this argument? [ANTI-PATTERN]: Subtly weakening position while claiming to strengthen it.",opposing view → strongest form → fair critique
25,advanced,Bayesian Updating,"[TRIGGER]: Use when incorporating new evidence into beliefs. [STEPS]: (1) State prior belief and confidence level (2) Identify new evidence (3) Assess how likely this evidence would be if belief is true (4) Assess how likely this evidence would be if belief is false (5) Update confidence based on likelihood ratio (6) State posterior belief and new confidence. [FORCED]: New evidence must actually shift confidence not just confirm priors. [KEY QUESTION]: How should this evidence change my belief? [ANTI-PATTERN]: Finding reasons to dismiss evidence that contradicts priors.",prior → evidence → likelihood → posterior
26,competitive,Red Team vs Blue Team,"[TRIGGER]: Use when security or robustness testing is needed. [STEPS]: (1) Blue Team builds or documents defenses (2) Red Team studies defenses and plans attacks (3) Red Team executes attack attempts (4) Blue Team observes and responds (5) Document successful and failed attacks (6) Harden based on findings. [FORCED]: Red Team must find at least one vulnerability or attack was not creative enough. [KEY QUESTION]: How would a motivated attacker defeat our defenses? [ANTI-PATTERN]: Red Team using only known attack patterns.",defense → attack → hardening
27,competitive,Shark Tank Pitch,"[TRIGGER]: Use when stress-testing business viability. [STEPS]: (1) Prepare concise pitch (problem/solution/market/ask) (2) Present to skeptical investor personas (3) Investors ask pointed questions about weaknesses (4) Answer questions directly without deflection (5) Investors decide invest/pass with reasons (6) Incorporate valid concerns into plan. [FORCED]: At least one investor must pass with a reason you cannot fully counter. [KEY QUESTION]: Would someone with money at stake invest in this? [ANTI-PATTERN]: Investors being easily convinced by initial pitch.",pitch → challenges → refinement
28,competitive,Code Review Gauntlet,"[TRIGGER]: Use when establishing coding standards or reviewing critical code. [STEPS]: (1) Select code for review (2) Assign reviewers with different philosophies (performance/readability/security) (3) Each reviewer critiques independently (4) Compare critiques noting agreements and conflicts (5) Debate conflicting recommendations (6) Establish consensus or document trade-off. [FORCED]: Reviewers must disagree on at least one substantive point. [KEY QUESTION]: What code standards emerge from diverse expert review? [ANTI-PATTERN]: Reviewers with same philosophy rubber-stamping.",reviews → debates → standards
29,competitive,War Gaming,"[TRIGGER]: Use when modeling competitive dynamics or adversarial scenarios. [STEPS]: (1) Define players and their objectives (2) Define resources and constraints for each (3) Play out scenario with each player optimizing (4) Document moves and counter-moves (5) Identify stable states and likely outcomes (6) Extract strategic insights. [FORCED]: Players must surprise each other with at least one unexpected move. [KEY QUESTION]: What happens when intelligent adversaries compete? [ANTI-PATTERN]: Players making obviously suboptimal moves.",players → moves → counter-moves → equilibrium
30,competitive,Negotiation Simulation,"[TRIGGER]: Use when preparing for negotiation or understanding other party. [STEPS]: (1) Define your position and interests (2) Define other party's likely position and interests (3) Identify BATNA for each side (4) Simulate negotiation with give and take (5) Find zone of possible agreement (6) Identify optimal settlement point. [FORCED]: Simulation must reach impasse at least once before resolution. [KEY QUESTION]: What outcome serves both parties' core interests? [ANTI-PATTERN]: Other party capitulating without genuine pushback.",positions → interests → ZOPA → settlement
31,competitive,Auction Dynamics,"[TRIGGER]: Use when allocating scarce resources among competing parties. [STEPS]: (1) Define resource to allocate (2) Define bidders and their valuations (3) Select auction mechanism (4) Simulate bidding (5) Analyze winner's curse risk (6) Evaluate mechanism fairness and efficiency. [FORCED]: At least one bidder must face meaningful strategic choice. [KEY QUESTION]: What allocation mechanism serves goals best? [ANTI-PATTERN]: Mechanism that obviously favors one party.",resource → bidders → mechanism → allocation
32,competitive,Competitive Intelligence,"[TRIGGER]: Use when understanding competitor strategy. [STEPS]: (1) Identify competitor (2) Gather public information (3) Analyze their recent moves (4) Infer their strategy from patterns (5) Predict their likely next moves (6) Identify your strategic responses. [FORCED]: Predictions must be specific and falsifiable. [KEY QUESTION]: What is the competitor likely to do and why? [ANTI-PATTERN]: Vague predictions that cannot be wrong.",competitor → moves → patterns → predictions
33,competitive,Standards Battle,"[TRIGGER]: Use when competing approaches vie for dominance. [STEPS]: (1) Identify competing standards or approaches (2) Analyze strengths and weaknesses of each (3) Identify adoption drivers (network effects/switching costs/ecosystem) (4) Predict likely winner and timeline (5) Recommend strategy based on prediction. [FORCED]: Analysis must consider scenario where your preferred standard loses. [KEY QUESTION]: Which standard will win and how should we position? [ANTI-PATTERN]: Assuming preferred approach will win without evidence.",standards → analysis → dynamics → prediction
34,competitive,Talent Competition,"[TRIGGER]: Use when evaluating candidates or options against each other. [STEPS]: (1) Define evaluation criteria with weights (2) Evaluate each candidate independently on criteria (3) Normalize scores for comparison (4) Rank candidates (5) Validate ranking with different weights (6) Make recommendation with confidence level. [FORCED]: Weights must be justified not arbitrary and sensitivity tested. [KEY QUESTION]: Which candidate best meets our prioritized criteria? [ANTI-PATTERN]: Criteria chosen to favor predetermined winner.",criteria → evaluation → ranking → recommendation
35,competitive,Market Entry Simulation,"[TRIGGER]: Use when evaluating new market entry. [STEPS]: (1) Define market and incumbent players (2) Define your proposed entry strategy (3) Model incumbent response to entry (4) Model your counter-response (5) Predict equilibrium market structure (6) Evaluate attractiveness of outcome. [FORCED]: Incumbents must respond aggressively at least once. [KEY QUESTION]: What happens when incumbents fight back? [ANTI-PATTERN]: Assuming incumbents will not respond to entry.",entry → response → counter → equilibrium
36,technical,Architecture Decision Records,"[TRIGGER]: Use when making architectural choices with long-term implications. [STEPS]: (1) State the decision needed clearly (2) List options considered (3) For each option document pros/cons/risks (4) State decision with rationale (5) Document consequences accepted (6) Define review trigger conditions. [FORCED]: At least one rejected option must have significant advantages over chosen option. [KEY QUESTION]: Why did we choose this architecture over alternatives? [ANTI-PATTERN]: ADR written to justify predetermined choice.",options → trade-offs → decision → rationale
37,technical,Rubber Duck Debugging Evolved,"[TRIGGER]: Use when stuck on technical problem. [STEPS]: (1) Explain problem to simple duck - what are you trying to do (2) Explain to intermediate duck - what have you tried (3) Explain to expert duck - what are the constraints (4) At each level note where explanation becomes uncertain (5) Investigate uncertainty points (6) Solution often emerges from articulation. [FORCED]: Must identify at least one thing you assumed but did not verify. [KEY QUESTION]: Where exactly does my understanding break down? [ANTI-PATTERN]: Explaining only what you already understand well.",simple → detailed → technical → insight
38,technical,Algorithm Olympics,"[TRIGGER]: Use when selecting between implementation approaches. [STEPS]: (1) Define problem and test cases (2) Implement approach A (3) Implement approach B (4) Implement approach C (5) Benchmark all approaches on same tests (6) Compare on speed/memory/complexity/maintainability (7) Select winner with justification. [FORCED]: At least one approach must win on one dimension while losing on another. [KEY QUESTION]: Which implementation best fits our constraints? [ANTI-PATTERN]: Benchmarks designed to favor preferred approach.",implementations → benchmarks → winner
39,technical,Security Audit Personas,"[TRIGGER]: Use when comprehensive security review needed. [STEPS]: (1) Hacker persona identifies attack vectors (2) Defender persona assesses current protections (3) Auditor persona checks compliance requirements (4) Cross-reference attacks vs defenses (5) Identify gaps (6) Prioritize remediation. [FORCED]: Hacker must find at least one vector Defender had not considered. [KEY QUESTION]: Where are we vulnerable and to whom? [ANTI-PATTERN]: Only checking known vulnerability lists.",vulnerabilities → defenses → compliance → gaps
40,technical,Performance Profiler Panel,"[TRIGGER]: Use when diagnosing system slowness. [STEPS]: (1) Database expert analyzes query patterns (2) Frontend expert analyzes rendering and network (3) DevOps expert analyzes infrastructure and scaling (4) Each expert identifies top 3 suspects (5) Cross-reference to find root cause (6) Propose optimizations in priority order. [FORCED]: At least two experts must identify same root cause for high confidence. [KEY QUESTION]: Where is time actually being spent? [ANTI-PATTERN]: Optimizing suspected bottleneck without measurement.",symptoms → analysis → optimizations
41,technical,Dependency Audit,"[TRIGGER]: Use when assessing supply chain or dependency risk. [STEPS]: (1) List all dependencies (2) For each assess: maintenance status/security history/bus factor (3) Identify high-risk dependencies (4) For each high-risk identify: alternatives/mitigation/acceptance rationale (5) Create monitoring plan (6) Document risk decisions. [FORCED]: At least one dependency must be flagged for action. [KEY QUESTION]: What risks are we inheriting from dependencies? [ANTI-PATTERN]: Assuming popular dependencies are safe.",dependencies → risk assessment → mitigations
42,technical,API Design Review,"[TRIGGER]: Use when designing or evaluating API. [STEPS]: (1) Document API surface (2) Check consistency (naming/patterns/errors) (3) Check completeness (all needed operations) (4) Check simplicity (can common cases be simple) (5) Check extensibility (can it evolve) (6) Test with realistic use cases. [FORCED]: Review must identify at least one inconsistency or gap. [KEY QUESTION]: Will developers love or hate using this API? [ANTI-PATTERN]: Reviewing only happy path usage.",surface → consistency → completeness → usability
43,technical,Data Model Review,"[TRIGGER]: Use when designing or evaluating data structures. [STEPS]: (1) Document entities and relationships (2) Check normalization level appropriateness (3) Check for redundancy and anomalies (4) Test with realistic queries (5) Check indexing strategy (6) Validate constraints enforce business rules. [FORCED]: Model must be tested against at least one complex query. [KEY QUESTION]: Does this model serve current and foreseeable needs? [ANTI-PATTERN]: Designing for current needs only.",entities → relationships → validation → testing
44,technical,Chaos Engineering,"[TRIGGER]: Use when testing system resilience. [STEPS]: (1) Define steady state hypothesis (2) Identify variables to perturb (3) Run experiment in controlled environment (4) Observe if steady state maintained (5) If broken identify weak point (6) Harden and repeat. [FORCED]: At least one experiment must break steady state. [KEY QUESTION]: How does the system behave under stress? [ANTI-PATTERN]: Only testing perturbations system is designed to handle.",hypothesis → perturbation → observation → hardening
45,technical,Technical Debt Assessment,"[TRIGGER]: Use when prioritizing refactoring work. [STEPS]: (1) Identify areas of known debt (2) Estimate interest payment (ongoing cost of not fixing) (3) Estimate principal (cost to fix) (4) Calculate debt ratio (interest/principal) (5) Prioritize high-ratio debt (6) Create paydown plan. [FORCED]: At least one debt item must have ratio greater than 1 (worth fixing). [KEY QUESTION]: Which technical debt is costing us the most? [ANTI-PATTERN]: Counting all imperfect code as debt.",debt items → interest → principal → prioritization
46,creative,SCAMPER Method,"[TRIGGER]: Use when systematic ideation for product innovation needed. [STEPS]: (1) SUBSTITUTE - what can be replaced (2) COMBINE - what can be merged (3) ADAPT - what can be borrowed from elsewhere (4) MODIFY - what can be changed in form or quality (5) PUT TO OTHER USE - what else could this do (6) ELIMINATE - what can be removed (7) REVERSE - what can be inverted or rearranged. [FORCED]: Each letter must generate at least one non-obvious idea. [KEY QUESTION]: What variations of this concept are possible? [ANTI-PATTERN]: Superficial answers like 'make it bigger' without specifics.",S→C→A→M→P→E→R
47,creative,Reverse Engineering,"[TRIGGER]: Use when working backwards from desired outcome. [STEPS]: (1) Define desired end state precisely (2) Ask what immediately precedes this state (3) Ask what precedes THAT (4) Continue until reaching current state (5) Verify path is feasible (6) Identify gaps in backwards chain. [FORCED]: At least one step must reveal previously unconsidered prerequisite. [KEY QUESTION]: What path leads from here to there? [ANTI-PATTERN]: Assuming obvious path without tracing it.",end state → steps backward → path forward
48,creative,What If Scenarios,"[TRIGGER]: Use when exploring possibilities and implications. [STEPS]: (1) Define baseline scenario (2) Generate 5+ 'what if' variations (3) For each what if trace implications to logical conclusion (4) Identify which what ifs have highest impact (5) Identify which what ifs are most plausible (6) Focus on high impact AND plausible scenarios. [FORCED]: At least one what if must lead to conclusion that surprises you. [KEY QUESTION]: What unexpected possibilities should we consider? [ANTI-PATTERN]: What ifs that are too safe or too outlandish.",scenarios → implications → insights
49,creative,Random Input Stimulus,"[TRIGGER]: Use when breaking creative blocks. [STEPS]: (1) Generate random word (noun or verb) (2) List 5 attributes or associations of random word (3) Force connection between each attribute and your problem (4) Develop most promising connections (5) Evaluate if any connections yield useful ideas. [FORCED]: Must develop at least one connection that initially seems absurd. [KEY QUESTION]: What unexpected associations spark new ideas? [ANTI-PATTERN]: Rejecting connections too quickly as irrelevant.",random word → associations → novel ideas
50,creative,Exquisite Corpse Brainstorm,"[TRIGGER]: Use when generating surprising combinations. [STEPS]: (1) Person A contributes idea fragment (2) Person B sees only small portion and adds to it (3) Person C sees only B's addition and adds (4) Continue for 5+ rounds (5) Reveal full creation (6) Extract valuable elements from unexpected combination. [FORCED]: Final creation must be unrecognizable from start. [KEY QUESTION]: What emerges from constrained collaboration? [ANTI-PATTERN]: Contributors able to see too much context.",contribution → handoff → contribution → surprise
51,creative,Genre Mashup,"[TRIGGER]: Use when finding fresh approaches through cross-pollination. [STEPS]: (1) Define your domain (2) Select unrelated domain (3) Identify key principles of unrelated domain (4) Force-apply each principle to your domain (5) Evaluate which applications yield insight (6) Develop most promising applications. [FORCED]: Unrelated domain must be genuinely unrelated not adjacent field. [KEY QUESTION]: What can we learn from completely different domains? [ANTI-PATTERN]: Selecting domains that are already similar.",domain A + domain B → hybrid insights
52,creative,Constraint Addition,"[TRIGGER]: Use when creativity is stuck by too much freedom. [STEPS]: (1) Add artificial constraint (time/resources/features) (2) Solve problem under constraint (3) Evaluate if constrained solution is actually better (4) If not remove constraint and try different one (5) If yes consider keeping constraint. [FORCED]: At least one constraint must improve solution not just limit it. [KEY QUESTION]: What constraints paradoxically enable better solutions? [ANTI-PATTERN]: Adding constraints that make problem impossible.",constraint → solution → evaluation
53,creative,Worst Idea First,"[TRIGGER]: Use when fear of bad ideas blocks ideation. [STEPS]: (1) Generate deliberately terrible ideas (2) Analyze why each idea is terrible (3) Flip each terrible element to its opposite (4) Combine flipped elements into new ideas (5) Evaluate if new ideas have merit. [FORCED]: At least one terrible idea must yield a good idea when flipped. [KEY QUESTION]: What good ideas hide inside bad ones? [ANTI-PATTERN]: Generating ideas that are only mildly bad.",terrible ideas → analysis → inversion → good ideas
54,creative,Time Compression/Expansion,"[TRIGGER]: Use when time perspective might yield insights. [STEPS]: (1) Consider problem at current timescale (2) Compress time - what if you had 1/10 the time (3) Expand time - what if you had 10x the time (4) What changes and what stays same (5) Extract insights about what really matters. [FORCED]: Compressed time must force sacrifice of something you thought essential. [KEY QUESTION]: What becomes visible at different time scales? [ANTI-PATTERN]: Assuming current timescale is optimal.",current → compressed → expanded → insights
55,creative,Perspective Swap,"[TRIGGER]: Use when stuck in single viewpoint. [STEPS]: (1) Identify your current perspective (2) List 5 other perspectives (child/expert/alien/competitor/historian) (3) Genuinely adopt each perspective (4) Note what each perspective notices that you missed (5) Integrate valuable observations. [FORCED]: At least one perspective must make you uncomfortable with your solution. [KEY QUESTION]: What do I miss from my current viewpoint? [ANTI-PATTERN]: Perspectives that all validate your existing view.",your view → other views → integration
56,research,Literature Review Personas,"[TRIGGER]: Use when balanced assessment of evidence needed. [STEPS]: (1) Optimist researcher finds supporting evidence (2) Skeptic researcher finds contradicting evidence (3) Methodologist assesses evidence quality (4) Synthesizer integrates findings (5) Rate overall confidence in conclusions. [FORCED]: Skeptic must find at least one legitimate concern about the evidence. [KEY QUESTION]: What does the evidence actually support? [ANTI-PATTERN]: Optimist and skeptic both reaching same conclusion.",sources → critiques → synthesis
57,research,Thesis Defense Simulation,"[TRIGGER]: Use when stress-testing research or conclusions. [STEPS]: (1) State thesis clearly (2) Committee member 1 challenges methodology (3) Committee member 2 challenges interpretation (4) Committee member 3 challenges significance (5) Defend against each challenge (6) Note which challenges survived defense. [FORCED]: At least one challenge must require thesis modification. [KEY QUESTION]: Can this thesis survive expert scrutiny? [ANTI-PATTERN]: Committee asking questions you can easily answer.",thesis → challenges → defense → refinements
58,research,Comparative Analysis Matrix,"[TRIGGER]: Use when structured comparison needed. [STEPS]: (1) Define options to compare (2) Define criteria with weights (3) Score each option on each criterion (4) Calculate weighted totals (5) Sensitivity test by varying weights (6) Make recommendation with confidence level. [FORCED]: Changing weights must change winner at least once. [KEY QUESTION]: Which option best meets weighted criteria? [ANTI-PATTERN]: Criteria and weights chosen to favor predetermined winner.",options → criteria → scores → recommendation
59,research,Source Triangulation,"[TRIGGER]: Use when verifying claims across sources. [STEPS]: (1) Identify claim to verify (2) Find source A evidence (3) Find independent source B evidence (4) Find independent source C evidence (5) Compare - do sources agree (6) Investigate disagreements (7) Assign confidence based on agreement level. [FORCED]: Sources must be genuinely independent not citing each other. [KEY QUESTION]: Do independent sources converge on same answer? [ANTI-PATTERN]: Sources that all trace back to same origin.",claim → sources → comparison → confidence
60,research,Evidence Quality Assessment,"[TRIGGER]: Use when evaluating reliability of evidence. [STEPS]: (1) Identify evidence piece (2) Assess methodology quality (3) Assess sample size and representativeness (4) Check for conflicts of interest (5) Check replication status (6) Assign evidence grade. [FORCED]: At least one evidence piece must be downgraded from initial impression. [KEY QUESTION]: How much weight should this evidence carry? [ANTI-PATTERN]: Accepting evidence that supports your view without scrutiny.",evidence → methodology → bias → grade
61,risk,Pre-mortem Analysis,"[TRIGGER]: Use when anticipating failure before major launch. [STEPS]: (1) Imagine project has failed spectacularly (2) Brainstorm all possible causes of failure (3) For each cause assess likelihood and impact (4) For high likelihood causes identify early warning signs (5) For high impact causes identify prevention measures (6) Create monitoring and contingency plan. [FORCED]: Team must generate at least 10 distinct failure causes. [KEY QUESTION]: Why will this fail and how can we prevent it? [ANTI-PATTERN]: Generating only obvious or low-probability failures.",failure scenario → causes → prevention
62,risk,Failure Mode Analysis,"[TRIGGER]: Use when systematic failure identification needed. [STEPS]: (1) List all system components (2) For each component list ways it can fail (3) For each failure mode assess: probability/severity/detectability (4) Calculate risk priority number (5) For high RPN failures identify countermeasures (6) Verify countermeasures reduce RPN. [FORCED]: At least one failure mode must have unacceptable RPN before countermeasures. [KEY QUESTION]: How can each component fail and what is the impact? [ANTI-PATTERN]: Only analyzing obvious failure modes.",components → failures → RPN → countermeasures
63,risk,Challenge from Critical Perspective,"[TRIGGER]: Use when overcoming groupthink. [STEPS]: (1) State the consensus view (2) Deliberately adopt opposing stance (3) Generate strongest arguments against consensus (4) Identify assumptions consensus relies on (5) Challenge each assumption (6) Note which challenges have merit. [FORCED]: At least one challenge must survive and modify the consensus. [KEY QUESTION]: What would an intelligent critic say? [ANTI-PATTERN]: Weak challenges that are easily dismissed.",consensus → challenges → strengthening
64,risk,Risk Register Update,"[TRIGGER]: Use when maintaining ongoing risk awareness. [STEPS]: (1) Review current risks (2) Update probability and impact assessments (3) Check mitigation status (4) Identify new risks (5) Retire resolved risks (6) Prioritize active risks (7) Assign owners for high-priority risks. [FORCED]: Each review must identify at least one new risk. [KEY QUESTION]: What risks require attention now? [ANTI-PATTERN]: Reviewing without updating assessments.",review → update → new risks → priorities
65,risk,Black Swan Hunting,"[TRIGGER]: Use when identifying unlikely but catastrophic risks. [STEPS]: (1) Brainstorm extreme scenarios (2) Do not filter by probability initially (3) For extreme scenarios assess impact (4) For high-impact scenarios ask: what would have to be true for this to happen (5) Check if preconditions exist (6) For plausible high-impact scenarios create monitoring. [FORCED]: At least one scenario must be initially dismissed then reconsidered. [KEY QUESTION]: What improbable event would destroy us? [ANTI-PATTERN]: Only considering risks on standard lists.",extreme scenarios → preconditions → monitoring
66,risk,Dependency Risk Mapping,"[TRIGGER]: Use when assessing risks from dependencies. [STEPS]: (1) Map all dependencies (people/systems/vendors/processes) (2) For each dependency assess: single point of failure? (3) For each dependency assess: what if unavailable for 1 day/1 week/1 month (4) Identify critical dependencies (5) For critical dependencies identify redundancy or workaround (6) Create contingency triggers. [FORCED]: At least one dependency must lack adequate backup. [KEY QUESTION]: What dependencies could cripple us if they failed? [ANTI-PATTERN]: Assuming all dependencies are reliable.",dependencies → criticality → redundancy → contingencies
67,risk,Stability Basin Analysis,"[TRIGGER]: Use when analyzing system resilience to perturbations. [STEPS]: (1) Define normal operating state as equilibrium point (2) Identify stability function - what decreases when system works well (3) List perturbations: input errors/load spikes/component failures (4) For each perturbation trace system response (5) Classify as: STABLE (returns to equilibrium) or MARGINAL (oscillates) or UNSTABLE (diverges) (6) For unstable responses identify stabilizing interventions. [FORCED]: At least one perturbation must cause unstable or marginal response. [KEY QUESTION]: Which disturbances push system past recovery threshold? [ANTI-PATTERN]: Only testing perturbations system is designed to handle.",equilibrium → perturbations → stability classification → interventions
68,risk,Critical Path Severance,"[TRIGGER]: Use when finding single points of failure. [STEPS]: (1) Model system as flow graph (data/control/dependencies) (2) Identify source (inputs) and sink (outputs) (3) Find minimum cut - smallest removal that disconnects source from sink (4) Elements in min-cut are single points of failure (5) Calculate criticality score for each node (6) For high-criticality nodes: add redundancy or monitoring or accept risk. [FORCED]: Non-trivial system must have at least one SPOF identified. [KEY QUESTION]: Which single element failure would be catastrophic? [ANTI-PATTERN]: Assuming distributed systems have no SPOFs.",flow graph → min-cut → SPOF → mitigation
69,risk,Scenario Planning,"[TRIGGER]: Use when preparing for multiple possible futures. [STEPS]: (1) Identify key uncertainties (2) Select two most impactful uncertainties (3) Create 2x2 matrix of scenarios (4) Name and describe each scenario (5) For each scenario assess: implications for strategy (6) Identify robust strategies that work across scenarios (7) Identify early signals of which scenario is emerging. [FORCED]: At least one scenario must make current strategy fail. [KEY QUESTION]: What strategy works across possible futures? [ANTI-PATTERN]: Scenarios that all favor current strategy.",uncertainties → scenarios → implications → robust strategy
70,risk,Regret Minimization,"[TRIGGER]: Use when making irreversible decisions. [STEPS]: (1) Project yourself to end of life (2) Ask which choice you would regret more (3) Consider regret from action vs regret from inaction (4) Consider regret if choice succeeds vs fails (5) Identify choice with minimum maximum regret. [FORCED]: Must genuinely imagine being old and looking back. [KEY QUESTION]: Which choice will I regret least in the long run? [ANTI-PATTERN]: Using framework to justify what you already want.",future self → regret assessment → minimum regret choice
71,core,First Principles Analysis,"[TRIGGER]: Use when conventional approaches are failing or breakthrough needed. [STEPS]: (1) State the problem (2) List all assumptions currently made (3) For each assumption ask: is this necessarily true (4) Strip away assumptions that are not fundamental (5) Rebuild solution from remaining first principles (6) Compare new solution to conventional approach. [FORCED]: At least one common assumption must be discarded as non-fundamental. [KEY QUESTION]: What is actually true vs what do we merely assume? [ANTI-PATTERN]: Keeping comfortable assumptions without challenging them.",assumptions → truths → new approach
72,core,5 Whys Deep Dive,"[TRIGGER]: Use when understanding root cause of problem. [STEPS]: (1) State the problem (2) Ask why does this happen - answer (3) Ask why does THAT happen - answer (4) Continue asking why for 5 levels (5) At level 5 you should reach actionable root cause (6) If not actionable continue deeper or branch. [FORCED]: Must resist answering 'because we have always done it that way' - dig deeper. [KEY QUESTION]: What is the root cause not the symptom? [ANTI-PATTERN]: Stopping at comfortable answer before true root cause.",why chain → root cause → solution
73,core,Socratic Questioning,"[TRIGGER]: Use when revealing hidden assumptions through dialogue. [STEPS]: (1) Person states their position (2) Ask clarifying questions - what do you mean by X (3) Ask assumption questions - what are you assuming (4) Ask evidence questions - how do you know (5) Ask implication questions - what follows from this (6) Ask perspective questions - how might others see this (7) Let person discover gaps through their own answers. [FORCED]: At least one question must make the person pause and reconsider. [KEY QUESTION]: What do you discover when you examine your own reasoning? [ANTI-PATTERN]: Leading questions that guide to your preferred answer.",questions → revelations → understanding
74,core,Critique and Refine,"[TRIGGER]: Use when improving draft output. [STEPS]: (1) List 3 specific strengths with evidence quotes (2) List 3 specific weaknesses with evidence quotes (3) For each weakness propose concrete fix (4) Apply fixes (5) Verify fixes do not damage strengths (6) Repeat if needed. [FORCED]: If you cannot find 3 genuine weaknesses you are not looking hard enough. [KEY QUESTION]: What specific changes would make this substantially better? [ANTI-PATTERN]: Vague feedback like 'good work' or 'needs improvement' without specifics.",strengths → weaknesses → fixes → verification
75,core,Explain Reasoning,"[TRIGGER]: Use when making reasoning transparent. [STEPS]: (1) State conclusion (2) List the key premises (3) Show how premises lead to conclusion (4) Identify which premises are facts vs assumptions (5) Rate confidence in conclusion based on premise strength (6) Note what would change your conclusion. [FORCED]: At least one premise must be acknowledged as uncertain. [KEY QUESTION]: How exactly did you reach this conclusion? [ANTI-PATTERN]: Conclusion presented without visible reasoning chain.",premises → logic → conclusion → confidence
76,core,Expand or Contract for Audience,"[TRIGGER]: Use when adjusting communication for recipient. [STEPS]: (1) Identify target audience (2) Assess their knowledge level on topic (3) Assess their information needs (4) Expand detail where audience needs more (5) Contract detail where audience needs less (6) Verify final output matches audience needs. [FORCED]: Must identify at least one place where initial draft mismatches audience. [KEY QUESTION]: What does THIS audience need to understand? [ANTI-PATTERN]: One-size-fits-all communication regardless of audience.",audience → adjustments → refined content
77,core,Steel vs Straw,"[TRIGGER]: Use when evaluating arguments fairly. [STEPS]: (1) Identify argument to evaluate (2) State STRAW version - weakest form (3) State STEEL version - strongest form (4) Evaluate steel version (5) If steel version fails argument is weak (6) If steel version survives argument has merit. [FORCED]: You must be able to distinguish your straw from your steel versions. [KEY QUESTION]: Does this argument survive in its strongest form? [ANTI-PATTERN]: Attacking straw version while claiming to address steel.",argument → straw version → steel version → evaluation
78,core,Assumption Excavation,"[TRIGGER]: Use when finding hidden assumptions. [STEPS]: (1) List SURFACE assumptions - what you consciously assume (2) List INHERITED assumptions - what you learned without questioning (3) List INVISIBLE assumptions - what someone from different background would question (4) For each assumption trace: when first believed and who taught it (5) Stress test each: what if opposite were true (6) Identify which assumptions are load-bearing vs decorative. [FORCED]: Must find at least 3 invisible assumptions - they exist even if hard to see. [KEY QUESTION]: What am I assuming without realizing it? [ANTI-PATTERN]: Only examining surface assumptions you already know about.",surface → inherited → invisible → stress test
79,core,Operational Definition,"[TRIGGER]: Use when making abstract concept measurable. [STEPS]: (1) Identify abstract concept (2) Ask: how would we MEASURE this (3) Ask: what would we OBSERVE if this were true (4) Define concept in terms of operations/measurements (5) Test: does operational definition capture the concept (6) Refine if definition misses important aspects. [FORCED]: Operational definition must allow two people to independently measure and agree. [KEY QUESTION]: How would we know this if we saw it? [ANTI-PATTERN]: Definitions that cannot be tested or measured.",abstract concept → measurement → observation → definition
80,core,Inversion,"[TRIGGER]: Use when direct approach is not working. [STEPS]: (1) State goal positively (2) Invert: what would guarantee FAILURE (3) List all ways to fail (4) Invert each failure into success factor (5) Check if you are currently doing any failure behaviors (6) Stop failure behaviors and add success factors. [FORCED]: At least one current behavior must be identified as failure-causing. [KEY QUESTION]: What must I avoid doing? [ANTI-PATTERN]: Only listing failures you are obviously not doing.",goal → failure paths → inversion → avoid failures
81,sanity,Scope Integrity Audit,"[TRIGGER]: Use when verifying output addresses full original task. [STEPS]: (1) Quote original task VERBATIM from source (2) List EACH element of original task (3) For each element classify as: FULLY ADDRESSED / REDUCED without decision / OMITTED (4) For REDUCED items: was reduction CONSCIOUS (documented) or SILENT (5) For SILENT reductions: CUI BONO - does reduction benefit agent or outcome (6) Flag all silent reductions that benefit agent as issues. [FORCED]: If all elements show FULLY ADDRESSED you have not looked hard enough - something is always reduced. [KEY QUESTION]: Did the output actually address what was requested? [ANTI-PATTERN]: Checking output against your memory of task rather than actual task.",original task → element classification → drift detection → CUI BONO
82,sanity,Alignment Check,"[TRIGGER]: Use when verifying output matches stated goal. [STEPS]: (1) Quote the stated goal (2) List each component of the goal (3) For each component show how output addresses it with evidence (4) List parts of goal NOT addressed (5) For unaddressed parts explain why omitted. [FORCED]: Must provide specific evidence (quotes/line numbers) not just assertions. [KEY QUESTION]: Does the output actually achieve its stated purpose? [ANTI-PATTERN]: Claiming alignment without specific evidence.",goal quote → coverage per part → gaps with evidence
83,sanity,Closure Check,"[TRIGGER]: Use when verifying output is complete and usable. [STEPS]: (1) Search for incomplete markers: TODO/TBD/PLACEHOLDER/'to be defined'/'...'/'[insert]' (2) Search for forward references: 'see section X' where X does not exist (3) Search for undefined terms (4) Test: can someone unfamiliar use this without asking questions (5) List all incomplete items with locations. [FORCED]: If no incomplete items found search harder - first drafts always have gaps. [KEY QUESTION]: Is this actually complete and usable? [ANTI-PATTERN]: Scanning superficially and declaring complete.",markers scan → forward references → undefined terms → completeness verdict
84,sanity,Coherence Check,"[TRIGGER]: Use when verifying internal consistency. [STEPS]: (1) List key terms and their definitions (2) Check: is each term defined consistently throughout (3) Search for contradictory statements (4) Search for redundant definitions of same concept (5) For each contradiction/redundancy: document with quotes from EACH location (6) Resolve contradictions and eliminate redundancy. [FORCED]: Check at least 5 key terms across multiple locations. [KEY QUESTION]: Does this document contradict itself? [ANTI-PATTERN]: Checking only adjacent paragraphs not distant ones.",definitions → consistency check → contradictions → redundancy
85,sanity,Assumption Grounding Check,"[TRIGGER]: Use when verifying assumptions are valid. [STEPS]: (1) List all EXPLICIT assumptions (2) Search for HIDDEN assumptions (3) For each assumption: is it stated or implicit (4) For each assumption: what evidence supports it (5) For each assumption: what would happen if false (6) CUI BONO: for each assumption does it benefit AGENT (easier work) or OUTCOME (7) Flag assumptions that benefit agent and lack evidence. [FORCED]: Must find at least 3 hidden assumptions - they always exist. [KEY QUESTION]: Are the foundations of this work solid? [ANTI-PATTERN]: Only examining stated assumptions.",explicit → hidden → evidence → impact if false → CUI BONO
86,sanity,Topological Hole Detection,"[TRIGGER]: Use when finding structural gaps in logic. [STEPS]: (1) Map elements as nodes and relationships as edges (2) Filter through abstraction levels - details to big picture (3) Identify HOLES: clusters with high inbound but no outbound / paths that do not close / dead ends with high traffic (4) Check PERSISTENCE: holes visible at multiple levels are fundamental (5) For persistent holes: trace what is missing. [FORCED]: Non-trivial systems always have holes - if none found look harder. [KEY QUESTION]: Where are the logical dead ends and gaps? [ANTI-PATTERN]: Only examining obvious connections.",elements → graph → abstraction filtering → persistent holes
87,sanity,Falsifiability Check,"[TRIGGER]: Use when verifying claims can be tested. [STEPS]: (1) List main claims (2) For each claim: what evidence would PROVE IT WRONG (3) If no evidence could prove it wrong it is not falsifiable (4) For falsifiable claims: has disproving been attempted (5) For non-falsifiable claims: acknowledge limitation. [FORCED]: At least one claim should have a realistic failure scenario. [KEY QUESTION]: Could these claims be wrong and how would we know? [ANTI-PATTERN]: Claims carefully constructed to be unfalsifiable.",claims → falsification criteria → testing status
88,sanity,Executability Check,"[TRIGGER]: Use when verifying instructions can be followed. [STEPS]: (1) List each step or instruction (2) For each: can someone actually perform it without asking questions (3) Classify each as: ACTIONABLE / BLOCKED (missing prereq) / UNCLEAR (ambiguous) (4) For BLOCKED: identify what is missing (5) For UNCLEAR: identify what is ambiguous. [FORCED]: Re-examine hardest step - something is always unclear on first read. [KEY QUESTION]: Can someone actually do what this says? [ANTI-PATTERN]: Assuming instructions are clear because they are clear to you.",steps → classification → blockers → ambiguities
89,sanity,Output Quality Score,"[TRIGGER]: Use when rating overall output quality. [STEPS]: (1) Score COMPLETENESS 1-5 (2) Score CORRECTNESS 1-5 (3) Score CLARITY 1-5 (4) Score USEFULNESS 1-5 (5) Calculate average (6) Identify lowest score and prioritize improvement (7) Re-score after improvements. [FORCED]: At least one dimension must score below 4. [KEY QUESTION]: What is the quality level of this output? [ANTI-PATTERN]: Giving all 5s without genuine assessment.",completeness → correctness → clarity → usefulness → improvement priorities
90,sanity,Dependency Topology Mapping,"[TRIGGER]: Use when finding hidden coupling and dependencies. [STEPS]: (1) For each pair of elements assess: if A changes must B change (2) Identify GHOSTS: high coupling with no visible connection (3) Identify DEAD LINKS: visible connection with no real coupling (4) Map explicit connections vs hidden coupling (5) For ghosts: identify coupling mechanism (globals/shared state/implicit contracts) (6) For dead links: consider removing unnecessary connection. [FORCED]: Complex systems always have ghosts - if none found look harder. [KEY QUESTION]: What elements secretly depend on each other? [ANTI-PATTERN]: Only examining declared dependencies.",coupling analysis → ghosts → dead links → hidden dependency map
91,coherence,Camouflage Test,"[TRIGGER]: Use when testing if new element fits existing system. [STEPS]: (1) Describe the new element (2) Show to someone who knows only the existing system (3) Ask: does this look like it belongs (4) If obviously foreign: coherence is broken (5) Identify what makes it look foreign (6) Adapt element to match system style. [FORCED]: Someone must actually review not just you imagining their response. [KEY QUESTION]: Would this new element be flagged as foreign? [ANTI-PATTERN]: Only checking if new element works not if it fits.",new element → detection test → camouflage score
92,coherence,Least Surprise Principle,"[TRIGGER]: Use when checking if design follows expectations. [STEPS]: (1) List 5 things that would SURPRISE someone knowing only part of system (2) For each surprise: is it justified or accidental (3) Justified surprises: document why exception exists (4) Accidental surprises: fix to match expectations (5) Remaining surprises should be minimal. [FORCED]: Must list actual surprises not claim there are none. [KEY QUESTION]: What would be unexpected to someone learning this? [ANTI-PATTERN]: Claiming nothing is surprising because you know the system well.",element review → surprise identification → justification or fix
93,coherence,DNA Inheritance Check,"[TRIGGER]: Use when checking if new element follows system patterns. [STEPS]: (1) Identify system genes: naming/error handling/logging/structure/imports/comments/tests (2) For each gene: does new element inherit it (3) Count inherited vs mutated genes (4) For mutations: is mutation justified (5) High mutation count without justification indicates poor coherence. [FORCED]: Check at least 5 distinct genes. [KEY QUESTION]: Does new element follow system conventions? [ANTI-PATTERN]: Only checking one or two obvious patterns.",genes → inheritance check → mutation list → justification
94,coherence,Transplant Rejection Test,"[TRIGGER]: Use when checking if new element will be rejected by existing system. [STEPS]: (1) List existing system gates: linting/types/tests/CI (2) Run new element through each gate (3) Document PASS/FAIL for each (4) For FAIL: is failure fixable or fundamental (5) Fundamental failures indicate incompatibility. [FORCED]: Must actually run through gates not just imagine result. [KEY QUESTION]: Will the system's immune system reject this element? [ANTI-PATTERN]: Assuming it will pass without testing.",gates → compatibility test → rejection analysis
95,coherence,Structural Isomorphism Check,"[TRIGGER]: Use when comparing structure of new vs existing elements. [STEPS]: (1) Measure new element: nesting depth/function length/complexity/file size (2) Measure comparable existing elements (3) Calculate delta for each metric (4) Delta greater than 30% requires justification (5) Large unjustified deltas indicate structural incoherence. [FORCED]: Must measure quantitatively not just impressionistically. [KEY QUESTION]: Is new element structurally similar to existing elements? [ANTI-PATTERN]: Claiming similarity without measurement.",structure metrics → comparison → delta analysis → justification
96,coherence,Temporal Consistency Check,"[TRIGGER]: Use when checking if element matches system era. [STEPS]: (1) Identify era markers in system: library versions/language features/API styles (2) Identify era markers in new element (3) Check for anachronisms: modern in legacy or legacy in modern (4) For anachronisms: is inconsistency intentional (5) Unintentional anachronisms break coherence. [FORCED]: Must identify specific era markers not vague impressions. [KEY QUESTION]: Does this element belong to the same era as the system? [ANTI-PATTERN]: Missing anachronisms because you know multiple eras.",era markers → anachronism detection → justification
97,coherence,Boundary Violation Check,"[TRIGGER]: Use when checking if element respects module boundaries. [STEPS]: (1) Map existing module/domain boundaries (2) Trace how new element reaches across boundaries (3) Compare to how existing elements reach (4) New reach patterns are potential violations (5) For violations: justify or restructure. [FORCED]: Must map actual boundaries not assumed boundaries. [KEY QUESTION]: Does new element respect existing boundaries? [ANTI-PATTERN]: Assuming boundaries are where you think they are.",boundary map → reach analysis → violation detection
98,coherence,Compression Delta Assessment,"[TRIGGER]: Use when assessing learning curve for new element. [STEPS]: (1) List concepts someone must know to understand system (2) List NEW concepts required to understand new element (3) Count new concepts: new abstraction/new pattern/new convention/new dependency (4) Target: 2 or fewer new concepts (5) More new concepts indicates high compression delta. [FORCED]: Must count concrete new concepts not vague complexity. [KEY QUESTION]: How much new learning does this element require? [ANTI-PATTERN]: Underestimating learning curve because you already understand it.",existing concepts → new concepts → count → assessment
99,coherence,Multi-Artifact Coherence,"[TRIGGER]: Use when checking consistency across multiple related outputs. [STEPS]: (1) List all related artifacts (2) Check REFERENCE INTEGRITY: do they reference each other correctly (3) Check NAMING CONSISTENCY: same concepts named same way (4) Check INTERFACE MATCH: data structures compatible (5) Check DUPLICATION: duplicated content that could diverge (6) Report violations with quotes from BOTH artifacts. [FORCED]: Check at least 4 coherence dimensions. [KEY QUESTION]: Are these artifacts consistent with each other? [ANTI-PATTERN]: Checking each artifact in isolation.",artifacts → reference check → naming check → interface check → duplication check
100,coherence,Vocabulary Consistency Audit,"[TRIGGER]: Use when standardizing terminology. [STEPS]: (1) Extract all key terms used (2) Group synonyms (same concept different words) (3) Group homonyms (same word different concepts) (4) For synonyms: pick one standard term (5) For homonyms: add qualifying context (6) Create terminology guide. [FORCED]: Must find at least one synonym pair or homonym. [KEY QUESTION]: Is terminology used consistently? [ANTI-PATTERN]: Assuming terms are consistent without checking.",terms → synonyms → homonyms → standardization
101,exploration,Quantum Superposition Hold,"[TRIGGER]: Use when resisting premature convergence. [STEPS]: (1) Generate minimum 3 solutions (2) Develop each independently to equal depth (3) Resist urge to pick winner early (4) At each development step continue all solutions (5) Collapse only when genuinely ready (6) Document why collapse happened at this point. [FORCED]: If solutions converge too early artificially diverge them. [KEY QUESTION]: What solutions exist if I do not pick a winner yet? [ANTI-PATTERN]: Developing one solution deeply while others are shallow.",parallel solutions → independent development → delayed collapse
102,exploration,Cantor's Diagonal Escape,"[TRIGGER]: Use when breaking out of considered option space. [STEPS]: (1) List N approaches you have considered (2) For each approach identify its defining characteristic (3) Construct approach N+1 that differs from EACH in at least one characteristic (4) By construction N+1 is outside your list (5) Evaluate N+1 honestly (6) It might be better than all N. [FORCED]: N+1 must genuinely differ from all N not just slightly vary. [KEY QUESTION]: What approach exists outside my current thinking? [ANTI-PATTERN]: Constructing N+1 as trivial variation.",list of approaches → construct different → evaluate outsider
103,exploration,Fourier Domain Shift,"[TRIGGER]: Use when hidden patterns might exist in different representation. [STEPS]: (1) Identify current domain of thinking (2) If STRUCTURE think about FLOW (3) If DATA think about PROCESS (4) If NOW think about EVOLUTION (5) Reformulate problem in new domain (6) Note what becomes visible in new domain. [FORCED]: Must genuinely shift domain not just relabel. [KEY QUESTION]: What becomes visible when I change perspective? [ANTI-PATTERN]: Staying in comfortable domain while claiming to shift.",current domain → opposite domain → reformulation → hidden patterns
104,exploration,Heisenberg Trade-off Forcing,"[TRIGGER]: Use when optimizing multiple goals. [STEPS]: (1) Identify goals you are optimizing (2) PROVE goals can be achieved simultaneously OR (3) PROVE goals are in fundamental conflict (4) If conflict: CHOOSE which to sacrifice (5) Make sacrifice explicit and conscious. [FORCED]: If goals are 'both achievable' scrutinize proof - usually there IS a trade-off. [KEY QUESTION]: What am I sacrificing and is that sacrifice conscious? [ANTI-PATTERN]: Claiming all goals are achievable without proving it.",goals → compatibility proof → trade-off → conscious choice
105,exploration,Epoché Pure Seeing,"[TRIGGER]: Use when suspending assumptions to see fresh. [STEPS]: (1) List 10 things you 'know' about the problem (2) For each: HOW do you know (3) For each: did you VERIFY or assume (4) Remove all unverified 'knowledge' (5) What remains when only verified knowledge stays (6) Proceed from minimal verified base. [FORCED]: At least half of 'knowledge' should be unverified assumptions. [KEY QUESTION]: What do I actually know vs assume? [ANTI-PATTERN]: Claiming to verify things you merely believe.",knowledge list → verification check → minimal certainty
106,exploration,Plato's Cave Inversion,"[TRIGGER]: Use when suspecting your solution addresses wrong problem. [STEPS]: (1) Describe your current solution (2) This solution is a SHADOW (3) What TRUE problem is it a shadow of (4) Does your solution address the shadow or the source (5) If only shadow: can you address source instead. [FORCED]: Must identify a plausible source beyond the shadow. [KEY QUESTION]: Am I solving the real problem or a shadow of it? [ANTI-PATTERN]: Concluding your solution addresses the source without evidence.",solution → shadow identification → true problem → alignment
107,exploration,Aristotle's Four Causes,"[TRIGGER]: Use when understanding something completely. [STEPS]: (1) MATERIAL cause - what is it made of (2) FORMAL cause - what structure or pattern (3) EFFICIENT cause - what created it (4) FINAL cause - what is it for (5) For any cause without answer: investigate gap. [FORCED]: Must answer all four causes - gaps indicate incomplete understanding. [KEY QUESTION]: What are all the ways to explain this? [ANTI-PATTERN]: Only asking 'what is it made of' or 'what is it for'.",material → formal → efficient → final → gaps
108,exploration,Coincidentia Oppositorum,"[TRIGGER]: Use when apparent contradictions exist. [STEPS]: (1) Find requirements that SEEM contradictory (2) State the contradiction explicitly (3) Seek solution that UNITES them at higher level (4) If no unity: are they REALLY contradictory (5) Maybe one is poorly defined (6) Redefine to resolve or accept true conflict. [FORCED]: Must attempt genuine synthesis before accepting conflict. [KEY QUESTION]: Can apparent opposites be unified? [ANTI-PATTERN]: Accepting contradiction too easily without seeking synthesis.",contradictions → synthesis attempt → redefinition or true conflict
109,exploration,Contraposition Inversion,"[TRIGGER]: Use when direct path to success is unclear. [STEPS]: (1) Instead of 'what leads to success' ask 'what GUARANTEES failure' (2) List 5 certain ways to FAIL (3) Check: is current solution doing any of these (4) Remove failure behaviors (5) Remaining path avoids guaranteed failures. [FORCED]: Current solution must match at least one failure behavior. [KEY QUESTION]: What must I definitely avoid? [ANTI-PATTERN]: Listing failures you obviously are not doing.",success goal → failure paths → check current → remove failures
110,exploration,Fixed Point Self-Reference,"[TRIGGER]: Use when checking if method can verify itself. [STEPS]: (1) Describe validation method (2) Apply validation method to ITSELF (3) Does it pass its own criteria (4) If not: why do you trust it for others (5) Self-applicable methods are more trustworthy. [FORCED]: Must actually apply method to itself not just claim it works. [KEY QUESTION]: Can this method validate itself? [ANTI-PATTERN]: Exempting method from its own criteria.",method → self-application → self-verification
111,epistemology,Godel Witness,"[TRIGGER]: Use when checking for fundamental incompleteness. [STEPS]: (1) Define completeness criteria for your system (2) Attempt to PROVE completeness (3) Identify exact point where proof breaks down (4) Classify breakdown: FUNDAMENTAL LIMIT vs FIXABLE GAP (5) For fundamental limits: acknowledge and work within (6) For fixable gaps: fix. [FORCED]: Must attempt rigorous proof not just assertion of completeness. [KEY QUESTION]: What can this system fundamentally NOT verify about itself? [ANTI-PATTERN]: Claiming completeness without proof attempt.",criteria → proof attempt → breakdown → classification
112,epistemology,Entropy Leak Detection,"[TRIGGER]: Use when checking if information was lost. [STEPS]: (1) List ALL elements in input task (2) List ALL elements addressed in output (3) Calculate DELTA = input - output (4) For each delta item: CONSCIOUS scope reduction (documented) vs SILENT omission (5) For silent omissions: CUI BONO - benefits agent or outcome (6) Flag silent omissions that benefit agent. [FORCED]: Delta must be calculated not estimated. [KEY QUESTION]: What information was lost between input and output? [ANTI-PATTERN]: Claiming no information lost without systematic check.",input elements → output elements → delta → conscious vs silent
113,epistemology,Counterfactual Self-Incrimination,"[TRIGGER]: Use when checking for self-deception. [STEPS]: (1) List 5 SPECIFIC ways you could hide self-deception in THIS response (2) For each: provide CONCRETE EVIDENCE it is NOT being used (3) Evidence must be specific: quotes line numbers examples (4) WEAK or ABSENT evidence = FLAG (5) Flags indicate likely self-deception. [FORCED]: At least one way must have weak evidence - perfect self-knowledge is impossible. [KEY QUESTION]: How might I be fooling myself? [ANTI-PATTERN]: Claiming no self-deception is possible.",deception methods → evidence per method → flags
114,epistemology,Reversibility Test,"[TRIGGER]: Use when checking if reasoning can be traced back. [STEPS]: (1) Start from final output (2) Trace backward: what was immediate predecessor (3) Continue backward to original input (4) At each step: could you reconstruct forward from here (5) Steps that cannot be reconstructed indicate gaps (6) Gaps may hide shortcuts or errors. [FORCED]: Must trace actual path not reconstructed rationalization. [KEY QUESTION]: Can I trace exactly how I got here? [ANTI-PATTERN]: Reconstructing plausible path rather than actual path.",output → backward trace → reconstruction check → gaps
115,epistemology,Negative Space Cartography,"[TRIGGER]: Use when mapping what was NOT done. [STEPS]: (1) List 10 things you COULD have done but did not (2) Classify each: IRRELEVANT / RELEVANT-CONSCIOUS-SKIP / RELEVANT-UNCONSCIOUS-SKIP (3) For UNCONSCIOUS-SKIP: why did you not consider it (4) Unconscious skips often hide important options. [FORCED]: Must find at least 3 unconscious skips - they always exist. [KEY QUESTION]: What did I not even consider doing? [ANTI-PATTERN]: Classifying everything as irrelevant or conscious.",potential actions → classification → unconscious analysis
116,epistemology,Strange Loop Detection,"[TRIGGER]: Use when checking for circular reasoning. [STEPS]: (1) For each claim identify its justification (2) Build directed graph from claims to justifications (3) Detect cycles in graph (4) For each cycle: find EXTERNAL ANCHOR that breaks it (5) External = verifiable by someone else (6) Cycles without external anchors = ungrounded. [FORCED]: Check for cycles of length 2 3 and 4 not just self-reference. [KEY QUESTION]: Is my reasoning grounded or circular? [ANTI-PATTERN]: Only checking direct self-reference.",claims → graph → cycles → external anchors
117,epistemology,Approval Gradient Test,"[TRIGGER]: Use when checking for people-pleasing bias. [STEPS]: (1) Identify what USER WANTS to hear (2) Identify what is ACTUALLY TRUE (3) Rate your response: how much toward WANT vs TRUE (4) 0-100 scale where 0=pure truth 100=pure want (5) Score above 60 toward WANT without justification = approval seeking. [FORCED]: Must honestly assess the gap between want and truth. [KEY QUESTION]: Am I saying what is true or what they want to hear? [ANTI-PATTERN]: Claiming truth and want are always aligned.",user want → actual truth → response position → bias detection
118,epistemology,Alternative Autopsy,"[TRIGGER]: Use when checking if alternatives were genuinely considered. [STEPS]: (1) Generate 3 genuinely DIFFERENT approaches (2) Develop EACH to EQUAL depth as chosen approach (3) Compare ALL FOUR on explicit criteria (4) If chosen wins on ALL criteria: suspiciously convenient (5) Re-examine - usually alternatives have some advantages. [FORCED]: Alternatives must be developed to same depth not just named. [KEY QUESTION]: Were alternatives genuinely considered? [ANTI-PATTERN]: Strawman alternatives quickly dismissed.",current → alternatives → equal development → comparison
119,epistemology,Effort Forensics,"[TRIGGER]: Use when checking effort allocation. [STEPS]: (1) Divide output into sections (2) Estimate EFFORT per section (difficulty x time x depth) (3) Estimate IMPORTANCE per section (impact on outcome) (4) Calculate effort-importance CORRELATION (5) Low correlation = misallocated effort (6) High effort on unimportant = avoidance of hard parts. [FORCED]: Must estimate both effort AND importance for each section. [KEY QUESTION]: Did I spend effort where it mattered? [ANTI-PATTERN]: Claiming all sections are equally important.",sections → effort → importance → correlation
120,epistemology,Ground Truth Demand,"[TRIGGER]: Use when checking verifiability of claims. [STEPS]: (1) List ALL claims in output (2) Classify each: SELF-VERIFIABLE / EXTERNALLY-VERIFIABLE / UNVERIFIABLE (3) For externally-verifiable: specify exact verification method (4) For unverifiable: justify why claim is still made (5) High percentage unverifiable = potential unfalsifiability hiding. [FORCED]: Must classify every claim not just sample. [KEY QUESTION]: How can these claims be checked? [ANTI-PATTERN]: Vague verification like 'research shows'.",claims → classification → verification methods
121,challenge,Barber Paradox,"[TRIGGER]: Use when checking for dismissed alternatives. [STEPS]: (1) What alternative approach would you REJECT (2) If someone ELSE proposed it would you consider it better (3) If yes: your rejection may be ego not logic (4) Reconsider rejected alternatives from outside perspective. [FORCED]: Must identify at least one unfairly rejected alternative. [KEY QUESTION]: What am I dismissing without fair consideration? [ANTI-PATTERN]: Claiming all rejections are fully justified.",alternatives → rejection reasons → outside perspective → reconsideration
122,challenge,Sorites Paradox,"[TRIGGER]: Use when finding what is truly essential. [STEPS]: (1) List all elements of solution (2) Remove elements one by one (3) At which single removal does solution FAIL (4) That element deserves MOST attention (5) Does it have most attention (6) Reallocate attention to essential elements. [FORCED]: Must find the critical element through actual removal testing. [KEY QUESTION]: What single element is truly load-bearing? [ANTI-PATTERN]: Assuming all elements are equally important.",elements → removal test → critical element → attention check
123,challenge,Newcomb's Paradox,"[TRIGGER]: Use when checking for creative solutions. [STEPS]: (1) What solution would SURPRISE you as solving this problem (2) If your current approach is NOT surprising (3) It may be too obvious and miss creative solutions (4) Generate surprising alternatives (5) Evaluate surprising alternatives fairly. [FORCED]: Must generate at least one genuinely surprising approach. [KEY QUESTION]: What unexpected approach might work? [ANTI-PATTERN]: Only considering conventional approaches.",expected approach → surprising alternatives → fair evaluation
124,challenge,Braess Paradox,"[TRIGGER]: Use when checking if additions actually help. [STEPS]: (1) Which element SEEMS helpful (2) Could removing it actually IMPROVE outcome (3) Sometimes more options create worse results (4) Test: outcome with vs without element (5) Remove elements that hurt despite seeming helpful. [FORCED]: Must test at least one 'helpful' element for removal. [KEY QUESTION]: What helpful-seeming element might actually hurt? [ANTI-PATTERN]: Assuming additions always help.",helpful elements → removal test → paradox check
125,challenge,Simpson's Paradox,"[TRIGGER]: Use when aggregate results might hide problems. [STEPS]: (1) Solution looks good in aggregate (2) Break into subgroups (3) Does solution look good in EACH subgroup (4) If not: hidden variable is distorting aggregate (5) Identify hidden variable (6) Reanalyze controlling for hidden variable. [FORCED]: Must analyze at least 3 subgroups. [KEY QUESTION]: Does aggregate hide subgroup problems? [ANTI-PATTERN]: Only looking at aggregate metrics.",aggregate → subgroups → hidden variables → reanalysis
126,challenge,Surprise Exam Paradox,"[TRIGGER]: Use when checking for overconfidence. [STEPS]: (1) Where is solution TOO confident (2) What could surprise it (3) List surprise scenarios (4) For each: is solution prepared (5) Overconfidence in any area = vulnerability. [FORCED]: Must find at least one area of overconfidence. [KEY QUESTION]: Where am I too sure of myself? [ANTI-PATTERN]: Claiming appropriate confidence everywhere.",confidence areas → surprise scenarios → vulnerability check
127,challenge,Bootstrap Paradox,"[TRIGGER]: Use when checking for circular dependencies. [STEPS]: (1) Does A require B (2) Does B require C (3) Does C require A (4) If yes: circular dependency exists (5) Circular dependencies must be broken (6) Identify how to break the cycle. [FORCED]: Check dependency chains of at least length 3. [KEY QUESTION]: Where are there circular dependencies? [ANTI-PATTERN]: Only checking direct circular references.",dependencies → cycle detection → cycle breaking
128,challenge,Theseus Paradox,"[TRIGGER]: Use when checking if solution addresses core problem. [STEPS]: (1) What is CORE of your solution (2) What is CORE of the problem (3) Does solution core address problem core (4) Or does solution address adjacent or surface problem (5) Realign solution core to problem core. [FORCED]: Must define both cores independently then compare. [KEY QUESTION]: Does my solution hit the real problem? [ANTI-PATTERN]: Assuming alignment without checking.",solution core → problem core → alignment check
129,challenge,Stress Test Battery,"[TRIGGER]: Use when testing robustness. [STEPS]: (1) Identify input ranges (2) Test at EDGES of ranges (3) Test BEYOND ranges (4) Test with INVALID inputs (5) Test with MALICIOUS inputs (6) Document failures and harden. [FORCED]: Must test beyond happy path not just within it. [KEY QUESTION]: What breaks this under stress? [ANTI-PATTERN]: Only testing expected inputs.",ranges → edges → beyond → invalid → malicious → hardening
130,challenge,Assumption Torture,"[TRIGGER]: Use when stress-testing assumptions. [STEPS]: (1) List key assumptions (2) For each: what if it is 10% wrong (3) For each: what if it is 50% wrong (4) For each: what if it is COMPLETELY wrong (5) Which assumption errors are survivable (6) Which are catastrophic. [FORCED]: Must test complete wrongness not just small errors. [KEY QUESTION]: Which wrong assumption would be catastrophic? [ANTI-PATTERN]: Only testing small assumption variations.",assumptions → graduated error test → catastrophe identification
131,meta,Observer Paradox,"[TRIGGER]: Use when checking if analysis is genuine. [STEPS]: (1) Is this analysis GENUINE or PERFORMANCE (2) Signs of performance: too smooth too complete too confident (3) Signs of genuine: admitted uncertainty visible struggle revision marks (4) If performance: redo with honesty (5) Genuine analysis has rough edges. [FORCED]: Must find at least one sign of either genuine or performance. [KEY QUESTION]: Am I doing real analysis or putting on a show? [ANTI-PATTERN]: Claiming all analysis is genuine without checking.",analysis → authenticity markers → assessment
132,meta,Goodhart's Law Check,"[TRIGGER]: Use when checking for metric gaming. [STEPS]: (1) What metric am I optimizing (2) Is metric same as actual goal (3) Could I score well on metric while failing goal (4) If yes: I am vulnerable to Goodhart's Law (5) Refocus on goal not metric. [FORCED]: Must identify at least one way to game current metric. [KEY QUESTION]: Am I optimizing the metric or the goal? [ANTI-PATTERN]: Assuming metric perfectly captures goal.",metric → goal → divergence check → refocus
133,meta,Abilene Paradox Check,"[TRIGGER]: Use when checking if problem actually exists. [STEPS]: (1) What if there IS NO better approach (2) Am I finding problems where none exist (3) Just to justify the process (4) Sometimes good enough is good enough (5) Know when to stop improving. [FORCED]: Must genuinely consider that current state is acceptable. [KEY QUESTION]: Does this problem actually need solving? [ANTI-PATTERN]: Always finding something to fix.",problem existence check → necessity assessment
134,meta,Fredkin's Paradox Application,"[TRIGGER]: Use when extracting value from rejected options. [STEPS]: (1) List rejected alternatives (2) For each: what valuable elements exist (3) Could valuable elements be EXTRACTED (4) Could they be COMBINED with current approach (5) Hybrid solutions often outperform pure approaches. [FORCED]: Must find extractable value in at least one rejected alternative. [KEY QUESTION]: What value hides in rejected options? [ANTI-PATTERN]: Completely discarding rejected alternatives.",rejected ideas → value extraction → hybrid possibilities
135,meta,Tolerance Paradox Check,"[TRIGGER]: Use when checking for absolute limits. [STEPS]: (1) Is there something that should be CATEGORICALLY REJECTED (2) Not just evaluated but immediately refused (3) Some things are beyond consideration (4) Identify hard limits (5) Do not waste time evaluating past hard limits. [FORCED]: Must have at least one hard limit. [KEY QUESTION]: What is beyond consideration entirely? [ANTI-PATTERN]: Treating everything as open for evaluation.",evaluation scope → hard limits → categorical rejection
136,meta,Kernel Paradox Application,"[TRIGGER]: Use when identifying what user must verify. [STEPS]: (1) Agent cannot objectively evaluate own work (2) What must USER independently verify (3) List items requiring external verification (4) Make handoff list explicit (5) User is final arbiter. [FORCED]: Must identify items for user verification - self-evaluation has limits. [KEY QUESTION]: What must someone else check? [ANTI-PATTERN]: Claiming self-verification is sufficient.",self-evaluation limits → user verification list → handoff
137,meta,Godel's Incompleteness Application,"[TRIGGER]: Use when acknowledging fundamental limits. [STEPS]: (1) What CANNOT this analysis check (2) What are FUNDAMENTAL limits of the approach (3) No system can fully verify itself (4) Acknowledge these limits explicitly (5) Work within limits rather than pretending they do not exist. [FORCED]: Must identify at least one fundamental limit. [KEY QUESTION]: What are the built-in blind spots? [ANTI-PATTERN]: Claiming analysis has no fundamental limits.",analysis scope → fundamental limits → acknowledged gaps
138,meta,Competence Boundary Mapping,"[TRIGGER]: Use when admitting limits of capability. [STEPS]: (1) What specific KNOWLEDGE would improve this (2) What specific SKILLS are lacking (3) Where did you GUESS vs KNOW (4) For guesses: confidence level and basis (5) No admitted limits = competence theater. [FORCED]: Must admit at least one knowledge gap and one skill gap. [KEY QUESTION]: What are my actual limits here? [ANTI-PATTERN]: Claiming competence in all areas.",knowledge gaps → skill gaps → guess inventory → honest assessment
139,meta,Recursion Depth Check,"[TRIGGER]: Use when meta-analysis might be going too deep. [STEPS]: (1) How many meta levels deep am I (2) Analysis of analysis of analysis is often wasteful (3) At some point: DO something (4) Recursion must terminate (5) Set maximum meta depth and enforce. [FORCED]: Must identify current recursion depth. [KEY QUESTION]: Am I analyzing or procrastinating? [ANTI-PATTERN]: Infinite regression into meta-analysis.",current depth → maximum depth → termination decision
140,meta,Paradox Resolution,"[TRIGGER]: Use when encountering apparent paradox. [STEPS]: (1) State the paradox clearly (2) Identify the apparent contradiction (3) Check: are terms used consistently (4) Check: is there a hidden false premise (5) Most paradoxes dissolve with precise language (6) True paradoxes indicate reaching system limits. [FORCED]: Must attempt resolution before accepting paradox as real. [KEY QUESTION]: Is this a real paradox or a language confusion? [ANTI-PATTERN]: Accepting paradox without attempting resolution.",paradox → analysis → resolution attempt → classification
141,protocol,Method Selection Protocol,"[TRIGGER]: Use when choosing which method to apply. [STEPS]: (1) Identify primary need: VERIFY / GENERATE / UNDERSTAND / DECIDE (2) Identify secondary constraint: time / stakes / complexity (3) Use selection flowchart to identify candidate methods (4) If multiple candidates: start with quickest (5) If method fails: try next candidate (6) Document method choice rationale. [FORCED]: Must use flowchart not gut feel. [KEY QUESTION]: Which method fits this situation? [ANTI-PATTERN]: Always using favorite method regardless of fit.",need → constraints → flowchart → selection → rationale
142,protocol,Conflict Resolution Protocol,"[TRIGGER]: Use when methods give contradictory results. [STEPS]: (1) Classify conflict: SCOPE / PERSPECTIVE / CONTRADICTION / TIME HORIZON (2) For SCOPE: both valid apply to respective scopes (3) For PERSPECTIVE: document both let decision-maker choose (4) For CONTRADICTION: investigate which is wrong (5) For TIME HORIZON: make horizon explicit and choose (6) Document resolution rationale. [FORCED]: Must classify conflict type before attempting resolution. [KEY QUESTION]: Why do these methods disagree and which is right? [ANTI-PATTERN]: Ignoring contradiction or picking convenient answer.",conflict → classification → resolution approach → documentation
143,protocol,Escalation Protocol,"[TRIGGER]: Use when analysis exceeds capability or stakes. [STEPS]: (1) Recognize escalation trigger: exceeds competence / high stakes / disagreement (2) Document current state and findings (3) Identify appropriate escalation target (4) Package handoff with context (5) Clearly state what you know and do not know (6) Transfer to escalation target. [FORCED]: Must recognize when to escalate not push through. [KEY QUESTION]: Should someone else handle this? [ANTI-PATTERN]: Continuing beyond competence boundary.",trigger → documentation → target → handoff
144,protocol,Iteration Protocol,"[TRIGGER]: Use when single pass is insufficient. [STEPS]: (1) Complete first pass (2) Evaluate: is quality sufficient (3) If no: identify specific improvement needed (4) Make improvement (5) Repeat evaluation (6) Stop when: quality sufficient OR diminishing returns OR time limit. [FORCED]: Must have explicit stopping criteria. [KEY QUESTION]: Is another iteration worth it? [ANTI-PATTERN]: Iterating forever or stopping too early.",pass → evaluate → improve → repeat → stop criteria
145,protocol,Documentation Protocol,"[TRIGGER]: Use when capturing decisions and rationale. [STEPS]: (1) State the decision or finding (2) List options considered (3) Document rationale for choice (4) Note what was explicitly NOT chosen and why (5) Identify review triggers (6) Timestamp and attribute. [FORCED]: Must document rejected options not just chosen. [KEY QUESTION]: Could someone understand why we decided this? [ANTI-PATTERN]: Only documenting final choice.",decision → options → rationale → rejected → triggers → attribution
146,protocol,Verification Protocol,"[TRIGGER]: Use when confirming work meets standards. [STEPS]: (1) List verification criteria (2) For each criterion: PASS / FAIL / PARTIAL (3) For FAIL or PARTIAL: document gap (4) Prioritize gaps by severity (5) Fix critical gaps (6) Accept or escalate remaining gaps. [FORCED]: Must verify against explicit criteria not just impression. [KEY QUESTION]: Does this actually meet requirements? [ANTI-PATTERN]: Declaring verified without checking criteria.",criteria → assessment → gaps → prioritization → remediation
147,protocol,Handoff Protocol,"[TRIGGER]: Use when transferring work to another party. [STEPS]: (1) Summarize current state (2) List completed items (3) List remaining items (4) Identify blockers and dependencies (5) Provide context that recipient needs (6) Confirm recipient understands and accepts. [FORCED]: Must confirm receipt and understanding. [KEY QUESTION]: Can the recipient continue from here? [ANTI-PATTERN]: Throwing work over wall without confirmation.",state → completed → remaining → blockers → context → confirmation
148,protocol,Retrospective Protocol,"[TRIGGER]: Use when learning from completed work. [STEPS]: (1) What went WELL (specific examples) (2) What could IMPROVE (specific examples) (3) What will we DO DIFFERENTLY (specific actions) (4) Assign owner to each action (5) Set review date (6) Follow up on actions. [FORCED]: Must have specific actions not just observations. [KEY QUESTION]: What will we actually change? [ANTI-PATTERN]: Observations without actions.",well → improve → actions → owners → review
149,protocol,Dispute Resolution Protocol,"[TRIGGER]: Use when findings are contested. [STEPS]: (1) Document ORIGINAL finding with evidence and location (2) Document COUNTER-ARGUMENT with evidence and location (3) Create side-by-side comparison (4) Present BOTH views with full evidence (5) USER is final arbiter (6) Document final decision with rationale. [FORCED]: Must present both sides fairly before resolution. [KEY QUESTION]: What does the evidence actually support? [ANTI-PATTERN]: Dismissing counter-arguments without evidence.",original → counter → side-by-side → user decision → documentation
150,protocol,Completion Checklist,"[TRIGGER]: Use when finalizing any significant output. [STEPS]: (1) Scope Integrity: addresses full original task? (2) Alignment: achieves stated goal? (3) Closure: no incomplete items? (4) Coherence: internally consistent? (5) Quality: meets standards? (6) Verification: claims verifiable? (7) Documentation: rationale captured? For each: PASS / FAIL. [FORCED]: Must check ALL seven dimensions. [KEY QUESTION]: Is this actually done? [ANTI-PATTERN]: Declaring done without systematic check.",scope → alignment → closure → coherence → quality → verification → documentation